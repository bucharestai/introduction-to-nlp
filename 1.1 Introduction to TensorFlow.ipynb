{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.1 Introduction to TensorFlow and Keras.ipynb","version":"0.3.2","provenance":[{"file_id":"1RTWiKoDctCaO4uc-GV2kQIYaeUyvvgME","timestamp":1540377968228}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"YLJYPJawiaue","colab_type":"text"},"cell_type":"markdown","source":["# Setup and version checks"]},{"metadata":{"id":"SHyTMfJ10zfI","colab_type":"code","colab":{}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"r43w8Sr80Mdy","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.keras as keras\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QDqTBwMK0WoA","colab_type":"code","outputId":"98cc5cf4-4e87-48df-af8e-ce0bee8005a6","executionInfo":{"status":"ok","timestamp":1540398651679,"user_tz":-120,"elapsed":600,"user":{"displayName":"Krzysztof Suwada","photoUrl":"https://lh5.googleusercontent.com/-o1roBIXf7Xw/AAAAAAAAAAI/AAAAAAAAAAo/CYjLEXg98xM/s64/photo.jpg","userId":"18334398126529369335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["\"TensorFlow version: {0}, Keras version {1}\".format(tf.__version__, keras.__version__)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'TensorFlow version: 1.12.0-rc1, Keras version 2.1.6-tf'"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"2xkbTcKFsnmQ","colab_type":"code","outputId":"d259870a-6970-4832-a7aa-502678d3dd9d","executionInfo":{"status":"ok","timestamp":1540398652584,"user_tz":-120,"elapsed":804,"user":{"displayName":"Krzysztof Suwada","photoUrl":"https://lh5.googleusercontent.com/-o1roBIXf7Xw/AAAAAAAAAAI/AAAAAAAAAAo/CYjLEXg98xM/s64/photo.jpg","userId":"18334398126529369335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["if not tf.test.is_gpu_available():\n","  print('GPU device not found, CPU only mode.')\n","else:\n","  print('Found GPU at: {}.'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU device not found, CPU only mode.\n"],"name":"stdout"}]},{"metadata":{"id":"_dUjohCxhREu","colab_type":"text"},"cell_type":"markdown","source":["# The IMDB dataset\n","We'll be working with \"IMDB dataset\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews."]},{"metadata":{"id":"EqcluULa02-F","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.datasets import imdb\n","import numpy as np\n","import pandas as pd\n","\n","MAX_WORDS = 10000\n","SKIP_TOP = 10\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=MAX_WORDS, skip_top=SKIP_TOP)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ib1B6l2vjQPQ","colab_type":"code","outputId":"2c4d42ee-486f-4f50-c605-c66b3561da5b","executionInfo":{"status":"ok","timestamp":1540398662377,"user_tz":-120,"elapsed":563,"user":{"displayName":"Krzysztof Suwada","photoUrl":"https://lh5.googleusercontent.com/-o1roBIXf7Xw/AAAAAAAAAAI/AAAAAAAAAAo/CYjLEXg98xM/s64/photo.jpg","userId":"18334398126529369335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["train_data.shape\n","train_labels.shape\n","\n","\n","test_data.shape\n","test_labels.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"execute_result","data":{"text/plain":["(25000,)"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"YCmdMqyfqjUt","colab_type":"text"},"cell_type":"markdown","source":["# TL;DR\n","Our task is to develop a machine learning algorithm that will be able to predict one of two classes $0$ or $1$ which can be interpreted as positive and negative comments. Ussually the class that is for us more interesting is denoted as $1$.\n","\n","\n","Let's formulate the task in more precise way.\n","\n","We want to predict $y \\in \\{0,1\\}$ given set of observations $x_1,\\ldots,x_n$, let's denote this as some unknow function $y=h(x;\\theta)$, where $\\theta$ is vector of parameters. \n","\n","More formaly we have a random variable $Y$ with Bernouli distribution with parameter $\\alpha$.\n","\n","\\begin{equation}\n","Y \\sim Bernouli(\\alpha)\n","\\end{equation}\n","\n","This means that $P(Y=1) = \\alpha$, and $P(Y=0) = 1 - \\alpha$.\n","We can rewrite as a one equation\n","\n","\\begin{equation}\n","p(y) = \\alpha^y \\cdot (1-\\alpha)^{1-y}\n","\\end{equation}\n","\n","## Exponential family\n","We say that a distribution belongs to the Exponetial Family if it has a form:\n","\n","\\begin{equation}\n","p(y;\\eta) = b(y) \\exp(\\eta^T T(y)-a(\\eta))\n","\\end{equation}\n","\n","where $\\eta$ is a natural or canonical parameter of distribution,\n","$T(y)$ is called a suffcient statistic and \n","$exp(-a(\\eta))$ is a normalization factor.\n","\n","We can rewrite the Bernouli distribution in a following form:\n","\n","\\begin{equation}\n","\\alpha^y \\cdot (1-\\alpha)^{1-y} = \\exp\\left(y \\log \\frac{\\alpha}{1-\\alpha}+log(1-\\alpha)\\right)\n","\\end{equation}\n","\n","It means that Bernouli distribution belong to the exponential family with:\n","\n","\\begin{equation}\n","\\eta = \\log \\frac{\\alpha}{1-\\alpha}\n","\\end{equation}\n","\n","or equaivalently\n","\\begin{equation}\n","\\alpha = \\frac{1}{1+\\exp(-\\eta)}\n","\\end{equation}\n","\n","The last equation has exactly the form of logistic function.\n","In case when $(Y|X;\\theta) \\sim Bernouli(\\alpha)$ than if we assume that $\\alpha$ has linear relationship with inputs $x_i$, $\\eta = \\theta^T x$:\n","\n","\\begin{align}\n","E(Y|X;\\theta) &=& \\alpha \\\\\n","&=&\\frac{1}{1+\\exp(-\\eta)} \\\\\n","&=&\\frac{1}{1+\\exp(-\\theta^T x)}\n","\\end{align}\n","\n","In general this family of models $g(\\eta) = E(T(y); \\eta)$, w call $g^{-1}$ a link function.\n","\n","Now we can establish relationship between $\\alpha$, $\\eta$, and $x$.\n","\n","\\begin{equation}\n","\\eta = \\log \\left(\\frac{\\alpha}{1-\\alpha} \\right) = \\theta^T x\n","\\end{equation}\n","\n","Please note that the expresion $\\frac{\\alpha}{1-\\alpha}$ is called the odds, and the above equation states that the relationship between the odds of beeing $1$ is linearly dependant on the\n","$\\theta^T x$.\n","\n","## Partameters estimation\n","\n","We group observations by $x_i$ which gives us a set of:\n","\n","\\begin{align}\n","x_1, n_1, y_1   & \\\\\n","x_2, n_2, y_2\t& \\\\\n","\\vdots & \\\\\n","x_m, n_m, y_m \t&\n","\\end{align}\n","\n","and joint probability function for maximum likelihood estimation is\n","\n","\\begin{equation}\n","L(\\alpha) = \\prod_{i=1}^m P(Y_i = y_i|x_i) = \\prod_{i=1}^m \\binom{n_i}{y_i} \\alpha_i^{y_i} (1-\\alpha_i)^{n_i-y_i}\n","\\end{equation}\n","\n","and the log-lokelihood\n","\n","\\begin{equation}\n","l(\\alpha) = \\sum_{i=1}^m \\binom{n_i}{y_i} +y_i \\log \\alpha_i + (n_i-y_i) \\log(1-\\alpha_i)\n","\\end{equation}\n","\n","To estimate the unknown vector $\\theta$ we need to find a minimum of the function above.\n","There are many solutions to find the minimum - unfortunately there is no closed-form formula for theta. In most of the cases a technique like Newton-Raphson or SGD is involved.\n"]},{"metadata":{"id":"3y8aq3zfviAD","colab_type":"text"},"cell_type":"markdown","source":["## Data preparations\n","Now we have to convert a list of word indices to a bag-of-words representation.\n","This means that for a list $[2, 7, 3, 5, 0]$ we want to have $[1, 0, 1, 1, 0, 1, 0, 1, 0, \\ldots, 0]$."]},{"metadata":{"id":"JE26ga1-v7X-","colab_type":"code","colab":{}},"cell_type":"code","source":["def bag_of_words_matrix(words_lists):\n","    results = np.zeros((len(words_lists), MAX_WORDS))\n","    for i, sequence in enumerate(words_lists):\n","        results[i, sequence] = 1.  \n","    return results\n","  \n","x_train = bag_of_words_matrix(train_data)\n","x_test = bag_of_words_matrix(test_data)\n","y_train = np.eye(2)[train_labels] #np.asarray(train_labels).astype('float32')\n","y_test = np.eye(2)[test_labels] #np.asarray(test_labels).astype('float32')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ldIGnbK5lWmY","colab_type":"code","colab":{}},"cell_type":"code","source":["learning_rate = 0.01\n","training_epochs = 1\n","batch_num_in_dataset = int(x_train.shape[0]/training_epochs)\n","batch_size = 100\n","output_dim = 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2kFZt1GitKJ1","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_next_batch(n, x_train, y_train):\n","    index = np.arange(0 , len(x_train))\n","    np.random.shuffle(index)\n","    samples = index[:n]\n","    return x_train[samples], y_train[samples]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ev1wJ3IduXr9","colab_type":"code","outputId":"bee264a2-6463-41d6-ce1c-8d4104e04e15","executionInfo":{"status":"ok","timestamp":1540398671712,"user_tz":-120,"elapsed":521,"user":{"displayName":"Krzysztof Suwada","photoUrl":"https://lh5.googleusercontent.com/-o1roBIXf7Xw/AAAAAAAAAAI/AAAAAAAAAAo/CYjLEXg98xM/s64/photo.jpg","userId":"18334398126529369335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["get_next_batch(1, x_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[0., 0., 1., ..., 0., 0., 0.]]), array([[0., 1.]]))"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"MA4Fp-WvyNW1","colab_type":"code","outputId":"07b5d9af-6073-490f-faf1-09f42f9b3d9f","executionInfo":{"status":"ok","timestamp":1540398677497,"user_tz":-120,"elapsed":5666,"user":{"displayName":"Krzysztof Suwada","photoUrl":"https://lh5.googleusercontent.com/-o1roBIXf7Xw/AAAAAAAAAAI/AAAAAAAAAAo/CYjLEXg98xM/s64/photo.jpg","userId":"18334398126529369335"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"cell_type":"code","source":["# Parameters\n","learning_rate = 0.01\n","batch_size = 10\n","training_steps = 1000\n","display_step = 1\n","\n","# tf Graph Input\n","x = tf.placeholder(tf.float32, [None, MAX_WORDS]) \n","y = tf.placeholder(tf.float32, [None, output_dim]) \n","\n","# Set model weights\n","W = tf.Variable(tf.zeros([MAX_WORDS, output_dim]))\n","b = tf.Variable(tf.zeros([output_dim]))\n","\n","# Construct model\n","y_hat = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n","loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_hat), reduction_indices=1))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n","\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    for step in range(training_steps):\n","      batch_xs, batch_ys = get_next_batch(batch_size, x_train, y_train)\n","      _, c = sess.run([optimizer, loss], feed_dict={x: batch_xs,\n","                                                    y: batch_ys})\n","\n","      if step % 50 == 0: print(\"Loss: {0}\".format(c))\n","            \n","    print(\"Optimization Finished!\")\n","\n","    correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    \n","    train_accuracy = sess.run(accuracy, feed_dict={x: x_train, y: y_train})\n","    test_accuracy = sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n","    \n","    print('Train acc: {0}, Test acc: {1}'.format(train_accuracy, test_accuracy))\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loss: 0.6931471824645996\n","Loss: 0.5838429927825928\n","Loss: 0.6378467679023743\n","Loss: 0.6213328838348389\n","Loss: 0.5538224577903748\n","Loss: 0.4679785370826721\n","Loss: 0.5026615262031555\n","Loss: 0.4876132011413574\n","Loss: 0.5052644610404968\n","Loss: 0.37420785427093506\n","Loss: 0.44141674041748047\n","Loss: 0.5280390977859497\n","Loss: 0.6124923825263977\n","Loss: 0.336426317691803\n","Loss: 0.5220907926559448\n","Loss: 0.5226308703422546\n","Loss: 0.3691233992576599\n","Loss: 0.5824846625328064\n","Loss: 0.5126842260360718\n","Loss: 0.5951675176620483\n","Optimization Finished!\n","Train acc: 0.8461999893188477, Test acc: 0.8339200019836426\n"],"name":"stdout"}]},{"metadata":{"id":"R1iMRl-Dtu-z","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}